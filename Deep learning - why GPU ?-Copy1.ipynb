{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do we need GPU in deep learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPUs (Graphics Processing Units) are specialized computer hardware originally created to render images at high frame rates (most commonly images in video games). Since graphics texturing and shading require more matrix and vector operations executed in parallel than a CPU (Central Processing Unit) can reasonably handle, GPUs were made to perform these calculations more efficiently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU vs GPU — An Analogy.\n",
    "\n",
    "Considering CPU as a Ferrari and GPU as a huge truck to transport goods from Destination A to Destination B.,\n",
    "CPU(ferrari) can fetch small amounts of packages(3 goods) in the RAM quickly whereas GPU(truck) is slower but can fetch large amounts of memory(100 goods) in one turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Bandwidth:\n",
    "\n",
    "Bandwidth is one of the main reasons why GPUs are faster for computing than CPUs.\n",
    "\n",
    "Due to large datasets,the CPU takes up a lot of memory while training the model.\n",
    "\n",
    "The standalone GPU, on the other hand, comes with a dedicated VRAM memory. Thus, CPU’s memory can be used for other tasks. But, transferring large chunks of memory from CPU to GPU is a bigger challenge.\n",
    "\n",
    "Computing huge and complex jobs takes up a lot of clock cycles in CPU.The reason being,CPU takes up the jobs sequentially and it has a fewer number of cores than its counterpart,GPU.\n",
    "\n",
    "But, though GPUs are faster, the time taken to transfer huge amounts of data from CPU to GPU can lead to higher overhead time depending on the architecture of the processors.\n",
    "\n",
    "The best CPUs have about 50GB/s while the best GPUs have 750GB/s memory bandwidth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concluding:\n",
    "\n",
    "The High bandwidth, hiding the latency under thread parallelism and easily programmable registers makes GPU a lot faster than a CPU.\n",
    "\n",
    "Owing to the above factors, CPU can be used to train the model where data is relatively small. GPU is fit for training the deep learning systems in a long run for very large datasets. CPU can train a deep learning model quite slowly. GPU accelerates the training of the model.\n",
    "\n",
    "Hence, GPU is a better choice to train the Deep Learning Model efficiently and effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
